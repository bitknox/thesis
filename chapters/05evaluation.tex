\section{Evaluation} \label{sec:evaluation}
In this section we are going to evaluate \raven and compare it to a version of \beast's implementation of \raptorjoin that runs outside Spark. We will time the systems end to end of the joins which means the data load and the join itself are timed all together.
\subsection{Workload}
\label{sec:workload}
The workloads can be split into two major categories. The real-world datasets and synthetic datasets. The real-world datasets are meant to show real-world performance, allowing us to compare the different approaches. The synthetic sets are meant to test certain aspects of the approach where we control all the parameters, to examine exactly the subsystem or area of interest.
\subsubsection{Real World Data}
The following section contains an overview of real world data we are going to use for the evaluation. There are some relevant properties included. 
\paragraph{Vector Datasets} 
\mbox{} % :(
\begin{table}[H]
\begin{tabular}{|l|l|l|l|}
\hline
Dataset              & Size   & Vertices   &Polygons\\ \hline
Boundaries \cite{Boundaries} & 8.39MB & 548471     & 4293\\ \hline
Protected areas & 534MB  & 34861822   & 87251\\ \hline
Small Woody Features \cite{SmallWoodyFeaturesVector} & 1.59GB & 105349748  & 462665\\ \hline
\end{tabular}
\caption{The vector sets used along with size and number of vertices.}
\label{tab:vectordata}
\end{table}
We have selected three vector sets with varying sizes. Since our system only supports ESRI shapefiles\footnote{\url{https://webhelp.esri.com/arcgisdesktop/9.3/index.cfm?TopicName=Geoprocessing\%20considerations\%20for\%20shapefile\%20output}}, the hard limit on file size is 2GB. The sets are meant to show how we scale with the vector set size. The first the \textit{Boundaries} is a small vector set, but in terms of area, it covers the entire world. \textit{Protected areas} covers Europe, but has a lot more points to cover a smaller area. The final set \textit{Small Woody Features}. This set once again increases in size but covers a smaller area. This set only covers a subset of Spain.


\paragraph{Raster Datasets}
\mbox{} % :(
\begin{table}[H]
\begin{tabular}{|>{\raggedright\arraybackslash}p{2.5cm}|l|l|l|l|l|}
\hline
Dataset              & Size   & Compression & Bit depth & Colors  &Pixels\\ \hline
GLC2000 \cite{GLC2000}              & 826MB  & None        & 8         & 23      &659 M\\ \hline
Treecover \cite{Treecover} & 52GB  & None        & 8         & 98      &52 B\\ \hline
Small Woody Features \cite{SmallWoodyFeaturesRaster} & 6.04GB & LZW         & 8         & 3       &443.2 B\\ \hline
\end{tabular}
\caption{The raster sets used along with size, compression, bit depth, and number of colors.}
\label{tab:rasterdata}
\end{table}

The raster sets we have picked are likewise three different sizes, to see how it scales. The properties we have included in the table, are all parameters that can affect the join time for \raven. The sets that have been selected, guarantee that there is an overlap, no matter the vector set that it is joined with. \textit{GLC2000} covers the entire world. For Treecover, we have selected a subset that covers the entirety of Europe. Finally, the \textit{Small Woody Features} set covers the same area as the equivalent vector set.

\subsubsection{Synthetic Data}
This section details the synthetic datasets along with examples and purpose.
\paragraph{Raster (filtering workload)}
The percentages of values to select will be from 0\% to 100\% with two percent increments.

\begin{figure}[H]
\centering
    \begin{subfigure}[h]{0.35\textwidth}
        \includegraphics[width=\textwidth]{images/05evaluation/synthetic examples/selectivity_30.png}
        \caption{30 \%}
        \label{fig:y equals x}
    \end{subfigure}
    \hspace{1cm}
    \begin{subfigure}[h]{0.35\textwidth}
        \includegraphics[width=\textwidth]{images/05evaluation/synthetic examples/selectivity_75.png}
        \caption{75\%}
        \label{fig:three sin x}
    \end{subfigure}
    \caption{Comparison of different selectivity for Perlin noise.}
    \label{fig:selectivity}
\end{figure}

In figure \ref{fig:selectivity} we see examples of data used for selectivity testing. The white pixels match the percentage of selectivity. To make realistic landscapes, the base for these images is Perlin noise. The purpose of this experiment is to show how our approach reacts to the selectivity at the extremes. Values outside the selection are discarded early in the algorithm and a small selectivity would generate a small result set.
 
\paragraph{Raster (\kraster Compression)}
\begin{itemize}
    \item For Voronoi noise, we vary the number of tiles. For each of the tiles, we arrange them, such that each neighboring tile has a different colour. For the benchmark we vary the number of tiles between $2^2, 2^3, ... ,2^8$. An example of two of these tiles can be found in figure \ref{fig:voronoi_example}, where figure \ref{fig:voronoi_16} has 16 tiles and \ref{fig:voronoi_64} has 64 tiles.
    \item Perlin noise. To make our synthetic data resemble real-world data, we utilize Perlin noise to generate the \textit{base} landscape. We then map this landscape to a desired amount of different colors to be used in both bit depth testing and colour testing. An example of the type of landscapes we generate can be found in figure \ref{fig:perlin_example}.
\end{itemize}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.35\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/05evaluation/synthetic examples/voronoi16.png}
         \caption{16 tiles}
         \label{fig:voronoi_16}
     \end{subfigure}
     \hspace{1cm}
     \begin{subfigure}[b]{0.35\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/05evaluation/synthetic examples/voronoi64.png}
         \caption{64 tiles}
         \label{fig:voronoi_64}
     \end{subfigure}

        \caption{Comparison of different amounts of tiles for Voronoi noise.}
        \label{fig:voronoi_example}
\end{figure}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.35\textwidth]{images/05evaluation/synthetic examples/perlin.png}
    \caption{Example of Perlin noise with 7 different values.}
    \label{fig:perlin_example}
\end{figure}

\paragraph{Raster (number of values)} The benchmark will test 
$2^1, 2^2, ..., 2^{13}$ values with Perlin noise. 
This is to test the effects of the number of different raster values on our result type. The \kraster can compress the image more or less given how many equal values there are next to each other. Increasing the number of possible values, makes it more unlikely for the image to contain any groups of pixels with the same value.

\begin{figure}[H]
    \centering   %
\setkeys{Gin}{width=\linewidth}
\begin{subfigure}{.32\textwidth}
  \includegraphics{images/05evaluation/synthetic examples/colors_8.png}
  \caption{8 values}
  \label{fig:colors_08}
\end{subfigure}
\hfil
\begin{subfigure}{.32\textwidth}
  \includegraphics{images/05evaluation/synthetic examples/colors_16.png}
  \caption{16 values}
  \label{fig:colors_16}
\end{subfigure}
\hfil
\begin{subfigure}{.32\textwidth}
  \includegraphics{images/05evaluation/synthetic examples/colors_256.png}
  \caption{256 values}
  \label{fig:colors_256}
\end{subfigure}%
\caption{Examples of Perlin noise used for number of colors}
\label{fig:perlin_colors}
\end{figure}

\paragraph{Vector (Shape density - Uniform distribution)}
This set is for testing how the coverage of the raster data affects join time. The set is constructed by creating 10000 random polygons and placing them on a grid. Random shapes are generated, and their size is determined by the coverage we are aiming for.



\subsection{Implementation}
This section covers the implementation details of the benchmarks. It will cover the benchmarking framework \textit{eagle} and the runners, that are executed by the framework.
\subsubsection{Eagle} \label{sec:eagle}
\eagle is a framework for easily running containerized benchmarks. Eagle takes as input a JSON file that describes the experiments to run. It then orchestrates the necessary containers, mounts datasets, and executes the specified command inside the container. Finally, it collects the output from the benchmarked program, and automatically creates plots. This of course requires a consistent format for both input and output of the programs that are being benchmarked. For this purpose, we created thin wrappers that we have named \textit{runners}. These runners are responsible for taking input parameters, passing them correctly into the program that is to be executed, timing the runs, and finally printing a result, that is collected by \eagle. The runners we have created are:

\paragraph{\raven Runner} Responsible for executing \ravenjoin. Built using Java, such that \raven can be imported as a dependency. Since we want to test a hot run, the runner itself is also responsible for running the required iterations. 

\paragraph{Raptor Runner} Responsible for executing \raptorjoin. Like the \raven Runner, it imports our implementation of \raptorjoin as a dependency and is responsible for iterations.


This allows for easily configurable benchmarks, that can be run with very little oversight. All of the definitions used for benchmarking using eagle in this thesis are included in appendix \ref{app:bench}.

\subsubsection{RaptorJoin}
\label{sec:raptor-join}
To fairly evaluate \raptor \& \raven, we had to convert \raptor to a parallel single-machine algorithm. Since the datasets consist of multiple images, the simplest way to do this, is to have it handle multiple of these images at a time. Note that this also means that for single image datasets, it will not run in parallel, which is also the case for GLC2000. The rest of the implementation simply follows the paper \citetitle{raptorjoin} by \citet{raptorjoin}. Furthermore, it utilizes functionality from \citet{Beast-impl} to read data and compute intersections.


\subsection{Metrics}
\bigbreak
\begin{mdframed}[hidealllines=true,backgroundcolor=lightgray!20]
\paragraph*{Total time}
The main metric used throughout the benchmarks is the total time it takes to load, join and filter the data. For our system, the time can be split into the two categories below:
\paragraph*{Build time}
The time it takes to build the \kraster with DAC.
\paragraph*{Join Time} 
The time it takes for the join itself to complete. This includes time for filtering.
\end{mdframed}

\subsection{Setup}

The benchmarks are executed on a virtual machine with four cores and 16 GB of RAM. The java runtime is version 16 and it is configured to use 14 GB for all the real world datasets. To get more stable experiment results, all the first measures (cold starts) are excluded from the results. The first measures are often unstable and makes it harder to arrive at conclusions.


\subsection{Configuration}

The result type of \ravenjoin will always be the range value (see section \ref{sec:result-types}) as it has the most advantages while it is still comparable to the result of \raptorjoin. 

The selectivity of the filtered joins are small to highlight the efficiency of the algorithm for this case. As listed, the selectivity is set to 0.057\%, 0.059\% and 1.96\% for GLC2000, Treecover and Small Woody Features respectively.

The maximum and minimum number of children for \rstar nodes are fixed at 8 and 1 respectively for all benchmarks. This is because most of the time it does not make a significant performance difference for the join. It is very dataset dependent and there does not seem to be a clear pattern for the parameters influence of the join. 
\subsection{Comparative Results}
\label{sec:comparative-results}

This section covers all experiments conducted to compare \raven with \raptor. 

\subsubsection{Real-World Data}
\label{sec:real-data}

This section covers results for all the real-world datasets for both \ravenjoin and \raptorjoin. The datasets and their properties were outlined in \ref{sec:workload}. Results are shown both with filtering and without filtering, to highlight the benefits of the pushed-down filter approach. All the results for \ravenjoin are done with a cache, which means that to get these speeds, such a cache would need to be built first. Section \ref{sec:cache-building-times} covers the time it takes to build the cache.

\begin{table}[H]
\centering
    \begin{tabular}{|l|l|l|l|}
        \hline
         & Boundaries & Protected Areas & SWF (vector) \\ \hline
        read time & 44.1 ms & 21857 ms & 6244 ms \\ \hline
        build time & 4.5 ms & 86 ms & 774 ms \\ \hline
    \end{tabular}
    \caption{The time it takes to read the vector data and build the outer \str data structure.}
    \label{tab:vector-load-times}
\end{table}

Table \ref{tab:vector-load-times} shows The time spent loading and building the outer \rtree for the 3 different vector datasets. As expected, both loading and \rtree building takes longer for the larger datasets.

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.49\textwidth}
\centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/real world/Boundaries - Filter .png}
    \caption{Join time with filtering.}
    \label{fig:res-boundaries-filter}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.49\textwidth}
\centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/real world/Boundaries - No Filter .png}
    \caption{Join time without filtering.}
    \label{fig:res-boundaries-no-filter}
\end{subfigure}
\caption{Boundaries with all raster datasets.}
\end{figure}

Figure \ref{fig:res-boundaries-filter} shows the results for both \ravenjoin \& \raptorjoin for the vector set Boundaries and all three raster sets. Since boundaries is a small vector set, the time it takes to build and load is negligible. We show the times in table \ref{tab:vector-load-times}. This means that for all of the above results, the time is dominated by reading raster data, doing the join operation, and collecting results. Since this is a filtered result, the main advantage is the heavily reduced amount of results that have to be created. This goes for all three datasets, although it is more heavily visible for the small dataset GLC2000, which also lends itself to result compression. The benefit of which is more visible in figure \ref{fig:res-boundaries-no-filter}, since filtering does not play a factor.

The results in figure \ref{fig:res-boundaries-no-filter} show the same joins as in figure \ref{fig:res-boundaries-filter}, but without a filter. For GLC2000 \raven is 95\% faster, which here it is mainly due to the raptor implementation not being parallelized for a single image dataset. Section \ref{sec:raptor-join} goes into further detail on how it is implemented. For Treecover, the two joins perform equally. The reason being that we are unable to benefit from a filter, but still have expensive lookups to retrieve values. Furthermore, while we are able to compress results, the average range length for Treecover is not long enough to offset the loss from value retrieval. A histogram of ranges lengths can be found in figure \ref{fig:treecover-histogram}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{images/05evaluation/results/misc/hist_treecover.png}
    \caption{Histogram of range length from result of a join where everything in Treecover is selected.}
    \label{fig:treecover-histogram}
\end{figure}

The Small Woody Features dataset differs from the others since it is compressed. The size of the original dataset \& and the \kraster cache we build is very similar in size, meaning that we do not have to spend time decompressing while reading the same amount of data. Another reason is that the dataset lends itself nicely to result compression. Comparing it to both GLC2000 and Treecover that have an average range length of 2.92 and 2.86 respectively, Small Woody Features is much higher at 17.15. A full overview of range lengths for Small Woody Features can be found in figure \ref{fig:swf-history}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{images/05evaluation/results/misc/hist_woody.png}
    \caption{Histogram of range length from result of a join where everything in Small Woody Features (raster) is selected.}
    \label{fig:swf-history}
\end{figure}


\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.49\textwidth}
\centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/real world/Protected Areas - Filter .png}
    \caption{Join time with filtering.}
    \label{fig:res-protected-filter}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.49\textwidth}
\centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/real world/Protected Areas - No Filter .png}
    \caption{Join time without filtering.}
    \label{fig:res-protected-no-filter}
\end{subfigure}
\caption{Protected Areas with all raster datasets.}
\end{figure}

As we scale up the vector set size, we see that for small datasets \ravenjoin suffers a significant loss. We can again refer to table \ref{tab:vector-load-times} where it shows the load and build time for Protected Areas. A more interesting result is that of Small Woody Features (raster). Comparing figure \ref{fig:res-boundaries-no-filter} with figure \ref{fig:res-protected-no-filter}, we see that there is a difference of roughly 27 minutes, or around 63\% for \raptorjoin. To figure out why this is, we conducted a few experiments. We found that for the join using \textit{Boundaries} and \textit{Treecover}, around 6\% of the time is spent building \raptorjoin's \textit{flash indices}. For the join using \textit{Protected Areas}, this part of the join takes   Part of the reason for this is that Protected Areas produces around 21\% more results than Boundaries when joined with SWF (raster). 

Again for the filtered result, we see that there is a larger difference between \raven and \raptor, simply due to there being much fewer results.

% Explain filtering that makes treecover fast
%Explain why SWF is slower here than for boundaries

%Explain why treecover is suddenly so much slower. Explain why SWF is not affected as badly.
% Quick mention of GLC again.

\begin{figure}[H]
\centering
\begin{subfigure}[b]{0.49\textwidth}
\centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/real world/SWF (Vector) - Filter .png}
    \caption{Join time with filtering.}
    \label{fig:res-woody-filter}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.49\textwidth}
\centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/real world/SWF (Vector) - No Filter .png}
    \caption{Join time without filtering.}
    \label{fig:res-woody-no-filter}
\end{subfigure}
\caption{Small Woody Features (vector) with all raster datasets.}
\label{fig:res-woody}
\end{figure}

Figure \ref{fig:res-woody} shows the result for the Small Woody Features vector set. For the GLC2000 raster set, we again have to refer to table \ref{tab:vector-load-times} to see that almost all of the time, is spent reading the vector data. Comparing figure \ref{fig:res-woody-filter} with figure \ref{fig:res-woody-no-filter}, we see that for \raven, the join times are fairly similar. While this is the largest vector set being used for testing, it is also the one covering the smallest area. 

The join between SWF(Vector) and SWF is also the largest difference we see between \raven and \raptor. Referring back to table \ref{tab:rasterdata} we can see that SWF only has three colours. This means that we can benefit from range compression easily. Furthermore, since the vector data is a subset of the SWF raster data, any overlaps that we do find, should in theory result in longer ranges. This is also visible in figure \ref{fig:swf-history}, which shows range length distribution.



% Explain why there is not a significant difference from the filter version (eg. since there is a perfect overlap, in theory no values should be filtered)

For compressed raster datasets there is a large performance gap compared to \raptorjoin. Decompressing the data takes extra time and likewise is this time saved with the \kraster index. 


Joining the Treecover with no filter takes longer than \raptorjoin. This is because there is little time to save creating range values for this dataset and therefore the algorithm has to retrieve values at the maximum depth of the \kraster. This has a large cost even if the vector set only has a few large polygons as seen in figure \ref{fig:res-boundaries-no-filter} and \ref{fig:res-protected-no-filter}.







\subsubsection{Memory}
\label{sec:memory}

The memory consumption of the \kraster data structure is quite low, especially in tandem with a small partition size. Additionally, the results are compressed which in total mean the system can operate with little memory. In figure \ref{fig:mem-comp}, the memory consumption Raven and Raptor is compared by limiting it to the least amount of memory needed. Note that both systems are executed with four cores and the memory scale in proportion to the number of cores. \raven needed 50 MB while \raptor needed 800 MB to perform a join without crashing. Another reason for this large difference is that \raven can use any given partition size, whereas \raptor can only use the one that is built into the image it is joining. The benefit of using little memory is that the work to free memory will be less frequent.

\begin{figure}[H]
    \centering
    \includegraphics[height=6cm]{images/05evaluation/results/misc/memcomparison.png}
    \caption{Comparison of memory consumption for a join with SWF (raster, 2 images) and Boundaries.}
    \label{fig:mem-comp}
\end{figure}


\subsection{\raven Analysis}
\label{sec:raven-analysis}

This section covers an analysis of what gives an advantage in the system and how it is related to the data structures and approaches. 

\subsubsection{\kraster Compression}
\label{sec:k2-compression}
The compression rate of the \kraster depends mainly on 2 features of the raster data, the range of values present in the image (caused by the DAC), and the ability of the \kraster to compress the image into few tree nodes.
Table \ref{tab:bit-depth-size} shows that if the entire bit depth is utilised, there is roughly a linear relationship between the bit depth of the image and the size of the cache. That means that there is a logarithmic relationship between the range of values present in the image and the cache size.
Figure \ref{fig:k2-raster-compression} explores the second condition. Here, we also see a roughly linear relationship between the number of colours and the size of the resulting cache. Note that this depends on how the colours are distributed. Voronoi has large regions of the same values which are easily compressed by \kraster. If we imagined a simple checkered pattern of two values the \kraster itself would not be able to compress at all. This problem also spills into the join time which is explained in section \ref{sec:size-of-result}.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
    \hline
        Bit Depth & Cache Size \\ \hline
        8 bit & 15MB \\ \hline
        16 bit & 24MB \\ \hline
        24 bit & 33MB \\ \hline
    \end{tabular}
    \caption{The cache size for various images using different bit depths. In this test, all images are perlin noise and uses the entire range of values available with the given bit depth.}
    \label{tab:bit-depth-size}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[height=6cm]{images/05evaluation/results/misc/k2-compression.png}
    \caption{The size of the \kraster cache creates, as a function of the number of colours present in the image. This is done using Voronoi noise.}
    \label{fig:k2-raster-compression}
\end{figure}



\subsubsection{Size of Result}
\label{sec:size-of-result}

In figure \ref{fig:num-ranges}, we see a strong correlation between how much the \kraster can compress the image into nodes and how quickly we can join. In this benchmark, all pixels are joined. This can be explained by how we have to search the \kraster structure for values. The more ranges there are, the deeper the tree will be, and as such, we also have to search the much deeper tree, to extract values. Furthermore, we also have to create additional results, which also takes a significant amount of time. Figure \ref{fig:result_creation_time} shows the difference between a join where all the work is done, but no results are collected compared to a join, where we use the basic range value result type. This is a significant increase, and almost makes up 75\% of the time a join takes in total. This means that a way of reducing the amount of results can have a large impact on join time. Section \ref{sec:future_work} outlines a possible improvement, that would improve the amount we can compress results.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.35\textwidth}
    \centering
    \includegraphics[height=6cm]{images/05evaluation/results/misc/result_creation_time.png}
    \caption{Comparison of join times using the \textit{Treecover} raster set and \textit{Boundaries} vector set. For one of them, the join work is done, but the results are thrown away. The other is using the range value result type.}
    \label{fig:result_creation_time}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.6\textwidth}
    \centering
    \includegraphics[height=6cm]{images/05evaluation/results/misc/Join Time - Number of Ranges .png}
    \caption{Join time as a function of the number of ranges produced as a result of \ravenjoin. A preview of the dataset can be found in figure \ref{fig:perlin_colors}. \Repeater{4}{\\ \mbox{}} }
    \label{fig:num-ranges}
    \end{subfigure}
\end{figure}


It is also interesting to note, that for \raptorjoin, this would be a completely flat line, as it does not support compressing results into ranges. It would also not make sense to do this, since they would still be forced to iterate each pixel to create the ranges, whereas we can use the \kraster structure to efficiently extract ranges. This also speaks to the more general fact, that the dataset matters a lot more for \ravenjoin, than it does for \raptorjoin. 



\subsubsection{\kraster Search Comparison}
\label{sec:k2searchcomparison}

As mentioned in section \ref{sec:extract-cells}, we came up with a modification to the search methods for the \kraster tree that has better worst-case performance under certain reasonable assumptions. In this section, we will evaluate the two versions experimentally.

\begin{figure}[H]
    \centering
    \includegraphics[height=6cm]{images/05evaluation/results/misc/Old vs New Join (Filter) .png}
    \caption{Comparison of join time between two versions of \ravenjoin using the two versions of \textit{extractCells} described in section \ref{sec:extract-cells}. All joins in this plot use the \textit{Protected Areas} vector set and the same filter used in the filtered joins of section \ref{sec:real-data}.}
    \label{fig:old-vs-new}
\end{figure}

As seen in figure \ref{fig:old-vs-new}, The version of \raven using our new \textit{extractCells} method performs better than the old version overall, and significantly better on the \textit{Small Woody Features} raster dataset. One possible explanation for why \textit{Small Woody Features} is such an outlier is that that raster dataset has tiles that cover very small areas. This means that each tile will overlap with few geometries and for that reason it will have fewer pixel ranges next to each other horizontally.

\subsubsection{Selectivity}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/synthetic/Join Time - Selectivity .png}
    \caption{Join times for filters with different levels of selectivity.}
    \label{fig:filter-selectivity}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/synthetic/Vector Density .png}
    \caption{Join time as a function of the number of the area covered by the vector data. }
    \label{fig:vector-density}
    \end{subfigure}
\end{figure}


In figure \ref{fig:filter-selectivity}, we see that selecting everything performs the same as getting no results. This is due to the fact that each pixel range can be directly added to the results once the value has been accessed from the \kraster. In this scenario, there are pixel ranges that span across the whole image and there is only one pixel range per row in the image. The low selectivity gains performance as there are fewer results to be collected. At 50\% selectivity, the algorithm has to search a bit in the \kraster and at the same time there will be more pixel ranges in total. 

Figure \ref{fig:vector-density} shows that the join time of \ravenjoin depends on the spatial selectivity. This makes sense, since having a larger overlap between vector and raster data produces more results and therefore takes longer. The shape of the graph can be explained by the fact that the number of ranges created depends mainly on the height of each vector shape. This height grows with the square root of the spatial selectivity in our tests. Hence, the graph resembles a square root function.

\subsubsection{Cache Building Times}
\label{sec:cache-building-times}

To give a perspective of the one time cost of building the cache, we can take a look at the total creation time for the datasets. In figure \ref{fig:cache-build-write} the whole cache is built for all the raster data used in the evaluation and even though it takes a long time, it is only about the double of a single \raptorjoin of the same raster comparing to figure \ref{fig:res-boundaries-no-filter}. 

\begin{figure}[H]
\centering
    \includegraphics[width=0.5\textwidth]{images/05evaluation/results/misc/Cache Build & Write Times .png}
    \caption{Time taken to build \& write the cache for all raster sets.}
    \label{fig:cache-build-write}
\end{figure}

\subsubsection{\rtree Types}
\label{sec:r-tree-types}

To investigate the performance related to the \rtree data structure we test the datasets with a few different \rtree types. Note that generally there are not that many polygons in our dataset (see table \ref{tab:vectordata}) which means the \rtree will not be that deep.

\paragraph{\rtree Overlap}
Since the search performance of the \rtree is impacting the join time, we want to provide a metric of how efficient the search is. The search time is mostly affected by how the directorial nodes overlap each other. To compare how these overlaps differ between different \rtree{}s, an overlap ratio is calculated using the definition from  \citet{airtree}. If the ratio is 1.0, it means the query only traversed leaf nodes that had matches of entries. In table \ref{tab:overlap_ratio} there are overlap ratios for the \str, \rstar, and \rtree where the queried areas are the bounds of the individual "treecover" images.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}\hline  
         &  STR&  \rstar& r-tree
\\ \hline  
         Boundaries&  41.01\% &  49.27\% & 36.84\%
\\ \hline  
         Proteccted Areas&  26.68\%&  40.11\% & 25.82\%
\\ \hline  
         SWF (vector)&  25.05\%&  27.48\%& 25.24\%
\\ \hline 
    \end{tabular}
    \caption{Overlap ratio for different types of \rtree{}s with 3 different vector datasets. The minimum and maximum sub nodes for the \rtree nodes are 2 and 8 respectively.}
    \label{tab:overlap_ratio}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[height=6cm]{images/05evaluation/results/misc/Outer R-tree Type (Treecover) .png}
    \caption{Join time as a function of the number of the area covered by the vector data. }
    \label{fig:outer-r-tree}
\end{figure}

There are two separate uses of the \rtree in the system that can be differentiated. The first one is an outer tree that contains all the vector data and is queried by the raster tiles to retrieve the shapes within the tile bounds. The retrieved shapes will be added to a new inner \rtree that is used for the join algorithm. The effect of using various types of \rtree as the outer tree can be seen in figure \ref{fig:outer-r-tree}. The overlaps of the \str are not as good as the \rstar tree (see table \ref{tab:overlap_ratio}), but the building time is much faster for the \str, which more than makes up for the time lost on the worse overlap in most cases.

The type of the inner \rtree has a smaller impact on performance. We ran multiple benchmarks and computed that the average time taken to complete all of them. The \str came out on top, being 4.5\% faster than an \rtree. The \rstar, on the other hand, performed 6.6\% worse than the \rtree. If we instead compute the average relative difference compared to an \rtree the \str performs just 0.1\% worse on average, whereas the \rstar performs 6.2\% worse.
The plots for each run can be seen in appendix \ref{sec:inner-r-tree}. These experiments prompted us to rerun all the experiments involving real data again using an \str instead of the \rstar we had been using. These results, however, showed no clear advantage for either of them. Therefore, we concluded using an \rstar tree as the inner tree did not harm our performance in the benchmarks. These results can be found in appendix \ref{app:r-tree-comparison}.

\subsubsection{Result Type Performance}

\ravenjoin supports 3 different result types. Figure \ref{fig:result-type-performance} shows how each of them perform when joining the same data with the same filter. As expected, producing only ranges is significantly faster, especially when there is no filter or a filter with low selectivity. The reason for this is that it not only produces fewer results, but also avoids exploring the \kraster tree as much. Producing range values is faster than producing values, because the amount of results created is much smaller.

\begin{figure}[H]
    \centering
    \includegraphics[height=6cm]{images/05evaluation/results/misc/Result Type (GLC2000 - Boundaries) .png}
    \caption{The impact of different result types on the join time.}
    \label{fig:result-type-performance}
\end{figure}


\subsection{Result Summary}
If a cache for the raster set has been built, \ravenjoin outperforms \raptorjoin in most cases, especially when a filter on the raster values is applied to the join. If a cache has not already been built, \ravenjoin will take longer to compute the first join but will catch up to \raptorjoin after approximately 2-3 joins depending on the datasets.
\ravenjoin also has the advantage that it can work with far less memory than \raptorjoin can.

The size of the cache generated by the \ravenjoin algorithm depends logarithmically on the range of values present in the image, and linearly on the number of single-coloured regions present in the image.

The time taken by \ravenjoin to compute the join depends almost exclusively on the size of the produced result set.

We were able to determine that the optimal type of \rtree to use as the outer tree was the \str. The new \kraster search method we designed also proved to be better than the ones we had used previously for all datasets we tested.

We also saw that different result types affect the performance of the join significantly. As expected, range values are much faster than values while still providing the same information. If values are not needed, ranges can be used as they are even faster.

