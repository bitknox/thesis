\section{Evaluation} \label{sec:evaluation}
In this section we are going to evaluate Raven and compare it to a version of \beast's implementation of \raptorjoin that runs outside Spark. We will time the systems end to end of the joins which means the data load and the join itself are timed all together.
\subsection{Workload}
\label{sec:workload}
The workloads can be split into two major categories. The real-world datasets and synthetic datasets. The real-world datasets are meant to show real-world performance, allowing us to compare the different approaches. The synthetic sets are meant to test certain aspects of the approach where we control all the parameters, to examine exactly the subsystem or area of interest.
\subsubsection{Real world data}
The following section contains an overview of real world data we are going to use for the evaluation. There are some relevant properties included.
\paragraph{Vector sets} 
\mbox{} % :(
\begin{table}[H]
\begin{tabular}{|l|l|l|}
\hline
Dataset              & Size   & Vertices  \\ \hline
Boundaries           & 8.39MB & 548471    \\ \hline
Protected areas      & 534MB  & 34861822  \\ \hline
Small Woody Features & 1.59GB & 105349748 \\ \hline
\end{tabular}
\caption{The vector sets used along with size and number of vertices.}
\end{table}
We have selected three vector sets with varying sizes. Since our system only supports ESRI shapefiles\footnote{\todo[inline]{link}}, the hard limit on filesize is 2GB. The sets are meant to show how we scale with the vector set size. The first the \textit{Boundaries} is a small vector set, but in terms of area, it covers the entire world. \textit{Protected areas} covers Europe, but has a lot more points to cover a smaller area. The final set \textit{Small Woody Features}. This set once again increases in size but covers a smaller area. This set only covers a subset of Spain.


\paragraph{Raster sets}
\mbox{} % :(
\begin{table}[H]
\begin{tabular}{|>{\raggedright\arraybackslash}p{2.5cm}|l|l|l|l|l|}
\hline
Dataset              & Size   & Compression & Bit depth & Colors  &Pixels\\ \hline
GLC2000              & 826MB  & None        & 8         & 23      &659 M\\ \hline
Treecover            & 52GB  & None        & 8         & 98      &52 B\\ \hline
Small Woody Features & 6.04GB & LZW         & 8         & 3       &443.2 B\\ \hline
\end{tabular}
\caption{The raster sets used along with size, compression, bit depth, and number of colors.}
\end{table}

The raster sets we have picked are likewise three different sizes, to see how it scales. The properties we have included in the table, are all parameters that can affect the join time for \raven. The sets that have been selected, guarantee that there is an overlap, no matter the vector set that it is joined with. \textit{GLC2000} covers the entire world. For treecover, we have selected a subset that covers the entirety of Europe. Finally, the \textit{Small Woody Features} set covers the same area as the equivalent vector set.

\subsubsection{Synthetic data}
This section details the synthetic datasets along with examples and purpose.
\paragraph{Raster (filtering workload)}
Selectivity 100\%, 98,438\%, 96.875\% 93.75\%, 87.5\%, 75\%, 50\%, 25\%, 12.5\%, 6.25\%, 3.125\%, 1.562\%

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/05evaluation/synthetic examples/selectivity_30.png}
         \caption{30 \%}
         \label{fig:y equals x}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/05evaluation/synthetic examples/selectivity_75.png}
         \caption{75\%}
         \label{fig:three sin x}
     \end{subfigure}
     \hfill
        \caption{Comparison of different selectivity for Perlin noise.}
        \label{fig:selectivity}
\end{figure}

In figure \ref{fig:selectivity} we see examples of data used for selectivity testing. The white pixels match the percentage of selectivity. To make realistic landscapes, the base for these images is Perlin noise. The purpose of these datasets is to show how our approach improves once the selectivity percentage goes down.
 
\paragraph{Raster (K2 Compression)}
\begin{itemize}
    \item For Voronoi noise, we vary the number of tiles. For each of the tiles, we arrange them, such that each neighboring tile has a different colour. We vary the number of tiles between $2^2, 2^3, ... ,2^8$. An example of two of these tiles can be found in figure \ref{fig:voronoi_example}, where figure \ref{fig:voronoi_16} has 16 tiles and \ref{fig:voronoi_64} has 64 tiles.
    \item Perlin noise. To make our synthetic data resemble real-world data, we utilize Perlin noise to generate the \textit{base} landscape. We then map this landscape to a desired amount of different colors to be used in both bit-depth testing and colour testing. An example of the type of landscapes we generate can be found in figure \ref{fig:perlin_example}.
\end{itemize}

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/05evaluation/synthetic examples/voronoi16.png}
         \caption{16 tiles}
         \label{fig:voronoi_16}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.45\textwidth}
         \centering
         \includegraphics[width=\textwidth]{images/05evaluation/synthetic examples/voronoi64.png}
         \caption{64 tiles}
         \label{fig:voronoi_64}
     \end{subfigure}
     \hfill
        \caption{Comparison of different amounts of tiles for Voronoi noise.}
        \label{fig:voronoi_example}
\end{figure}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{images/05evaluation/synthetic examples/perlin.png}
    \caption{Example of Perlin noise with 7 different values.}
    \label{fig:perlin_example}
\end{figure}

\paragraph{Raster (number of values)}
$2^1, 2^2, ..., 2^{13}$ values with Perlin noise. 
This is to test the effects of the number of different raster values on our result type. The \kraster can compress the image more or less given how many equal values there are next to each other. Increasing the number of possible values, makes it more unlikely for the image to contain any groups of pixels with the same value.

\begin{figure}[H]
    \centering   %
\setkeys{Gin}{width=\linewidth}
\begin{subfigure}{.45\textwidth}
  \includegraphics{images/05evaluation/synthetic examples/colors_8.png}
  \caption{Perlin noise with 8 values}
  \label{fig:colors_08}
\end{subfigure}
\hfil
\begin{subfigure}{.45\textwidth}
  \includegraphics{images/05evaluation/synthetic examples/colors_16.png}
  \caption{Perlin noise with 16 values}
  \label{fig:colors_16}
\end{subfigure}

\begin{subfigure}{.45\textwidth}
  \includegraphics{images/05evaluation/synthetic examples/colors_256.png}
  \caption{Perlin noise with 256 values}
  \label{fig:colors_256}
\end{subfigure}%
\caption{Examples of Perlin noise used for number of colors}
\label{fig:perlin_colors}
\end{figure}

\paragraph{Vector (Shape density - Uniform distribution)}
This set is for testing how the coverage of the raster data affects join time. The set is constructed by creating 10000 random polygons and placing them on a grid. Random shapes are generated, and their size is determined by the coverage we are aiming for.

\subsection{Metrics}
\bigbreak
\begin{mdframed}[hidealllines=true,backgroundcolor=lightgray!20]
\paragraph*{Running time}
The main metric used throughout the benchmarks is running time. For our system, we split it into the two categories below:
\paragraph*{Build time}
The time it takes to build a \kraster tree.
\paragraph*{Join Time} 
The time it takes for the join itself to complete. This includes time for filtering.
\end{mdframed}

\subsection{Systems}

\subsection{Setup}

The benchmarks are executed on a virtual machine with four cores and 16 GB of RAM. The java runtime is version 16 and it is configured to use 14 GB for all the real world datasets.

\subsection{Configurations}
\begin{itemize}
    \item All real world vector with all real world raster
    \item Selectivity with square vector covering entire area
    \item Shape density with set Raster set OR synthetic set (static)
    \item Same as above, but with more complex shapes.
    \item Vector set covering entire area, raster varies between: Voronoi noise, Perlin noise \& Large squares. (We might want to tweak params for the noise...)
\end{itemize}

%glc (22-22): 0.057 \%
%treecover (81-84): 0.059 \%
%woody (1-1): 1.96\%

The result type of \ravenjoin will always be the range-value (see section \ref{sec:result-types}) as it has the most advantages while it is still comparable to the result of \raptorjoin. 

The selectivity of the filtered joins are small to highlight the efficiency of the algorithm for this case. As listed, the selectivity is set to 0.057\%, 0.059\% and 1.96\% for GLC2000, Treecover and Small Woody Features respectively.

The maximum and minimum number of children for \rstar nodes are fixed at 8 and 1 respectively for all benchmarks. This is because most of the time it does not make a significant performance difference for the join. It is very dataset dependent and there does not seem to be a clear pattern for the parameters influence of the join. 
\subsection{Results}
\subsubsection{Real world data}
\label{sec:real-data}
This section covers results for all the real-world datasets for both \ravenjoin and \raptorjoin. The datasets and their properties were outlined in \ref{sec:workload}. Results are shown both with filtering and without filtering, to highlight the benefits of the pushed-down filter approach. All the results for \ravenjoin are done with a cache, which means that to get these speeds, such a cache would need to be built first. Section \ref{sec:cache-building-times} covers the time it takes to build the cache.



\begin{table}[H]
\centering
    \begin{tabular}{|l|l|l|l|}
        \hline
         & boundaries & protected areas & woody \\ \hline
        read time & 57.7 ms & 14810 ms & 28700 ms \\ \hline
        build time & 5.5 ms & 80.5 ms & 651 ms \\ \hline
    \end{tabular}
    \caption{The time it takes to read the vector data and build outer \rtree data structure for it.}
    \label{tab:vector-load-times}
\end{table}

Table \ref{tab:vector-load-times} shows The time spent loading and building the outer \rtree for the 3 different vector datasets. As expected, both loading and \rtree building takes longer for the larger datasets.
 
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/05evaluation/results/real world/Join Time - Boundaries (Filter) .png}
    \caption{Join time of Boundaries with filtering.}
    \label{fig:res-boundaries-filter}
\end{figure}

Figure \ref{fig:res-boundaries-filter} shows the results for both \ravenjoin \& \raptorjoin for the vector set Boundaries and all three raster sets. Since boundaries is a small vector set, the time it takes to build and load is negligible. We show the times in table \ref{tab:vector-load-times}. This means that for all of the above results, the time is dominated by reading raster data, doing the join operation, and collecting results. Since this is a filtered result, the main advantage is the heavily reduced amount of results that have to be created. This goes for all three datasets, although it is more heavily visible for the small dataset GLC2000, which also lends itself to result compression. The benefit of which is more visible in figure \ref{fig:res-boundaries-no-filter}, since filtering does not play a factor.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/05evaluation/results/real world/Join Time - Boundaries (No Filter) .png}
    \caption{Join time of Boundaries without filtering.}
    \label{fig:res-boundaries-no-filter}
\end{figure}

The results in figure \ref{fig:res-boundaries-no-filter} show the same joins as in figure \ref{fig:res-boundaries-filter}, but without a filter. For GLC2000 \raven is 95\% faster, which here it is mainly due to result compression. For Treecover, we are about equal. In this case, we are not able to benefit from a filter nor result compression, as the values in Treecover rarely allow for ranges larger than \todo[inline]{REF HISTOGRAM}. 


\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/05evaluation/results/real world/Join Time - Protected Areas (Filter) .png}
    \caption{Join time of Protected Areas with filtering.}
    \label{fig:res-protected-filter}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/05evaluation/results/real world/Join Time - Protected Areas (No Filter) .png}
    \caption{Join time of Protected Areas without filtering.}
    \label{fig:res-protected-no-filter}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/05evaluation/results/real world/Join Time - Woody (Filter) .png}
    \caption{Join time of Small Woody Features with filtering.}
    \label{fig:res-woody-filter}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/05evaluation/results/real world/Join Time - Woody (No Filter) .png}
    \caption{Join time of Small Woody Features without filtering.}
    \label{fig:res-woody-no-filter}
\end{figure}

For compressed raster datasets there is a large performance gap compared to \raptorjoin. Decompressing the data takes extra time and likewise is this time saved with the \kraster index. 


Joining the tree cover with no filter takes longer than \raptorjoin. This is because there is little time to save creating range values for this dataset and therefore the algorithm has to retrieve values at the maximum depth of the \kraster. This has a large cost even if the vector set only has a few large polygons as seen in figure \ref{fig:res-boundaries-no-filter} and \ref{fig:res-protected-no-filter}.

\subsubsection{Synthetic data}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/synthetic/Join Time - Selectivity .png}
    \caption{Join times for filters with different levels of selectivity.}
    \label{fig:filter-selectivity}
\end{figure}

In figure \ref{fig:filter-selectivity}, we see that selecting everything performs the same as getting no results. This is due to the fact that each pixel range can be directly added to the results once the value has been accessed from the \kraster. In this scenario, there are pixel ranges that span across the whole image and there is only one pixel range per row in the image. The low selectivity gains performance as there are fewer results to be collected. At 50\% selectivity, the algorithm has to search a bit in the \kraster and at the same time there will be more pixel ranges in total. 

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/misc/Join Time - Number of Ranges .png}
    \caption{Join time as a function of the number of ranges produced as a result of \ravenjoin. A preview of the dataset can be found in figure \ref{fig:perlin_colors}. }
    \label{fig:num-ranges}
\end{figure}

In figure \ref{fig:num-ranges}, we see a strong correlation between how much the \kraster can compress the image into nodes and how quickly we can join. In this benchmark, all pixels are joined. This can be explained by how we have to search the \kraster structure for values. The more ranges there are, the deeper the tree will be, and as such, we also have to search the much deeper tree, to extract values. Furthermore, we also have to create additional results, which also takes a significant amount of time. Figure \ref{fig:result_creation_time} shows the difference between a join where all the work is done, but no results are collected compared to a join, where we use the basic range-value result type. This is a significant increase, and almost makes up 75\% of the time a join takes in total. This means that a way of reducing the amount of results can have a large impact on join time. Section \ref{sec:future_work} outlines a possible improvement, that would improve the amount we can compress results.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/05evaluation/results/misc/result_creation_time.png}
    \caption{Comparison of join times using the \textit{Treecover} raster set and \textit{Boundaries} vector set. For one of them, the join work is done, but the results are thrown away. The other is using the range-value result type.}
    \label{fig:result_creation_time}
\end{figure}

It is also interesting to note, that for \raptorjoin, this would be a completely flat line, as it does not support compressing results into ranges. It would also not make sense to do this, since they would still be forced to iterate each pixel to create the ranges, whereas we can use the \kraster structure to efficiently extract ranges. This also speaks to the more general fact, that the dataset matters a lot more for \ravenjoin, than it does for \raptorjoin. 


\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/synthetic/Vector Density .png}
    \caption{Join time as a function of the number of the area covered by the vector data. }
    \label{fig:vector-density}
\end{figure}

Figure \ref{fig:vector-density} shows that the join time of \ravenjoin depends on the spatial selectivity. This makes sense, since having a larger overlap between vector and raster data produces more results and therefore takes longer. The shape of the graph can be explained by the fact that the number of ranges created depends on the height of each vector shape. This height grows with the square root of the spatial selectivity in our tests. 

\todo[inline]{skal vi bevise at det er det der sker?}


factors that make us gain performance
\begin{itemize}
    \item our cached and compressed index.
    \item we can return a whole pixel range as result because we know it covers a single value.
    \item subsequent joins of compressed raster data.
    \item No sorting step for our pixel ranges.
\end{itemize}

\subsubsection{\kraster search comparison}
\label{sec:k2searchcomparison}

As mentioned in section \ref{sec:extract-cells}, we came up with a modification to the search methods for the \kraster tree that has better worst-case performance under certain reasonable assumptions. In this section, we will evaluate the two versions experimentally.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/misc/Old vs New Join (Filter) .png}
    \caption{Comparison of join time between two versions of \ravenjoin using the two versions of \textit{extractCells} described in section \ref{sec:extract-cells}. All joins in this plot use the \textit{Protected Areas} vector set and the same filter used in the filtered joins of section \ref{sec:real-data}.}
    \label{fig:old-vs-new}
\end{figure}

As seen in figure \ref{fig:old-vs-new}, The version of \raven using our new \textit{extractCells} method performs better than the old version overall, and significantly better on the \textit{Small Woody Features} raster dataset. One possible explanation for why \textit{Small Woody Features} is such an outlier is that that raster dataset has tiles that cover very small areas. This means that each tile will overlap with few geometries and for that reason it will have fewer pixel-ranges next to each other horizontally.

\subsubsection{Cache building times}
\label{sec:cache-building-times}

 \begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/misc/Cache Build & Write Times .png}
    \caption{Time taken to build \& write the cache for all raster sets.}
    \label{fig:cache-build-write}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/05evaluation/results/misc/Outer R-tree Type (Treecover) .png}
    \caption{Join time as a function of the number of the area covered by the vector data. }
    \label{fig:outer-r-tree}
\end{figure}

There are two separate uses of the \rtree in the system. The first one is an outer tree that contains all the vector data and is queried by the raster tiles to retrieve the shapes within the tile bounds. The retrieved shapes will be added to a new inner \rtree that is used for the join algorithm. The effect of using various types of \rtree as the outer tree can be seen in figure \ref{fig:outer-r-tree}. The overlaps of the \str are not as good as the \rstar tree (see table \ref{tab:overlap_ratio}), but the building time is much faster for the \str, which more than makes up for the time lost on the worse overlap in most cases.

The type of the inner \rtree has a smaller impact on performance. We ran multiple benchmarks and computed that the average time taken to complete all of them. The \str came out on top, being 4.5\% faster than an \rtree. The \rstar, on the other hand, performed 6.6\% worse than the \rtree. If we instead compute the average relative difference compared to an \rtree the \str performs just 0.1\% worse on average, whereas the \rstar performs 6.2\% worse.
The plots for each run can be seen in appendix \ref{sec:inner-r-tree}.

\subsection{Implementation details}
This section covers the implementation details of the benchmarks. It will cover the benchmarking framework \textit{eagle} and the runners, that are executed by the framework.
\subsubsection{Eagle} \label{sec:eagle}
\eagle is a framework for easily running containerized benchmarks. Eagle takes as input a JSON file that describes the experiments to run. It then orchestrates the necessary containers, mounts datasets, and executes the specified command inside the container. Finally, it collects the output from the benchmarked program, and automatically creates plots. This of course requires a consistent format for both input and output of the programs that are being benchmarked. For this purpose, we created thin wrappers that we have named \textit{runners}. These runners are responsible for taking input parameters, passing them correctly into the program that is to be executed, timing the runs, and finally printing a result, that is collected by \eagle. The runners we have created are:

\paragraph{Raven Runner} Responsible for executing \ravenjoin. Built using Java, such that \raven can be imported as a dependency. Since we want to test a hot run, the runner itself is also responsible for running the required iterations. 

\paragraph{Raptor Runner} Responsible for executing \raptorjoin. Like the raven runner, it imports our implementation of \raptorjoin as a dependency and is responsible for iterations.


This allows for easily configurable benchmarks, that can be run with very little oversight. All of the definitions used for benchmarking using eagle in this thesis are included in appendix \ref{app:bench}.

\subsection{RaptorJoin}
To fairly evaluate \raptor \& \raven, we had to convert \raptor to a parallel single-machine algorithm. Since the datasets consist of multiple images, the simplest way to do this, is to have it handle multiple of these images at a time. Note that this also means that for single image datasets, it will not run in parallel, which is also the case for GLC2000. The rest of the implementation simply follows the paper \citetitle{raptorjoin} by \citet{raptorjoin}. Furthermore, it utilizes functionality from \citet{Beast-impl} to read data and compute intersections.



