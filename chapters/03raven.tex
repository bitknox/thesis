\section{\raven} \label{sec:raven}
\raven is a system for computing and visualising raster-vector spatial joins. It uses an algorithm named \ravenjoin, which is a modified version of the algorithm described in \citetitle{k2rasterjoin} by \citet{k2rasterjoin}. It differentiates itself from the state-of-the-art system by being able to efficiently filter results based on raster values.

This section describes the different components of \raven. We first describe the data structures that serve as a foundation of the \ravenjoin algorithm. This is followed up by a description of the system, including data loading, the \ravenjoin algorithm, and visualizer.

\subsection{Data Structures}

\paragraph{\kraster} 
In order to efficiently filter values, \ravenjoin needs to be able to quickly retrieve information about all values present in some sub-matrix of the raster data. This is because it should be able to disregard large parts of the raster data if none of the values it contains are matched by the filter.

The \kraster data structure is a tree where every node corresponds to some part of the raster data. Nodes store the range of values present in the corresponding part. The root node of the tree corresponds to the entire image. Each node has $k^2$ children corresponding to equally-sized portions of the image from their parent. $k$ is a constant parameter chosen before building the data structure, it affects the size of the data structure and the time taken to build and query it. A \kraster tree can be queried about what range the values in a portion of the image has, as long as that portion has a corresponding node in the tree. If it does not, it is possible to combine queries of multiple nodes to achieve the desired result. The \kraster data structure also has the advantage that it compresses the image data considerably. An example of how an image can be converted to a tree storing value ranges can be seen in figure \ref{fig:k2raster-structure}.

To further reduce the size of the \kraster, instead of storing the ranges directly, they are stored as differences between the node in question and its parent. Specifically, each node will still store two numbers. One denoting how much larger the minimum value of its part of the data is compared to that of its parent. The other denoting how much smaller the maximum value is. In itself, this does not help much as it still needs to store 2 numbers. The improvement is caused by the fact that these values are further compressed using the DAC encoding \cite{DAC}. DAC compresses small values significantly better than large values. Storing differences instead of the ranges themselves help reduce the size of each number and therefore allows the DAC encoding to compress the data more.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/03method/k2tree.drawio-v2.png}
    \caption{Example of how a raster image can be compressed using the \kraster data structure. The figure is adapted from the paper \citetitle{k2raster} by \citet{k2raster}}
    \label{fig:k2raster-structure}
\end{figure}

\paragraph{\rtree} To query the vector data efficiently in a given area, a spatial index is used. One of the most common indices, is an \rtree \cite{rtree}. The data structure groups spatial data in close proximity given their Minimum Bounding Rectangle (\textit{MBR}). Region search queries traverse the overlapping nodes in the tree which quickly excludes a lot of data with no overlap from the search.

The \rstar \cite{rstartree} variant improves the search time of the tree by minimizing the overlaps of the nodes at the cost of longer build time. The vector data is loaded in as polygons that get inserted into the \rstar, one by one. It is also possible to bulk load the vector data with Sort Tile Recursive \cite{str} (\textit{STR}) and Overlap Minimizing Top-down \cite{omt} (\textit{OMT}), which is beneficial for large vector datasets. We are going use a library that can do STR bulk loading and create the \rstar variant. Ideally, we would do STR loading with \rstar nodes, but this was not available with the library we use.

\subsection{Data Loading}
To compute spatial joins \raven needs to support both vector and raster data formats. To limit the scope, we only support the following: esri formatted shapefiles\footnote{\url{https://www.esri.com/content/dam/esrisites/sitecore-archive/Files/Pdfs/library/whitepapers/pdfs/shapefile.pdf}} and GeoTiff\footnote{\url{https://www.loc.gov/preservation/digital/formats/fdd/fdd000279.shtml}}. For GeoTiff we support both inlined and sidecar World File information. The entire vector set is loaded into a \str. This is done using a single thread, which means that reading the vector set can become a bottleneck if the set becomes too large, especially in cases where the vector set is larger than the raster set. 

This initial index is used to decide whether there is an overlap between a raster tile bounds and any of the geometries. If no such overlap is found, we are able to discard the entire raster tile and avoid building \kraster. If there is an overlap, the tile is selected for further processing. The first step of the processing is to transform the vector data, such that it uses a common coordinate reference system. 

Once this transformation is done, a new tree is built using the transformed geometries. To further reduce memory, each raster tile is split into subtitles of a configurable size. This allows for only keeping very small amounts of raster data in memory at one time, while sacrificing speed. A measurement of this can be found in section \ref{sec:memory}. At this point, raster data is read and \kraster structures are built and paired with the accompanying geometries that were found to be overlapping. Figure \ref{fig:k-raster-r-tree-overlap} shows this pairing visually. The red shapes are polygons while the blue boxes are \rstar MBR outlines. The grey boxes represent \kraster nodes.\footnote{The boxes are only drawn to level 14 of the tree to prevent visual clutter} As expected, areas where pixels have the same value are more sparse. E.g. the water around Denmark. These pairs 



\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/03method/datastructures_denmarkv2.png}
    \caption{Example of an aligned \kraster and \str that is passed to the join.}
    \label{fig:k-raster-r-tree-overlap}
\end{figure}

\subsection{Join Algorithm}
\label{sec:raven-join}

As mentioned, \ravenjoin is based on the algorithm described in \citetitle{k2rasterjoin}. The main differences between that algorithm and \ravenjoin are
\begin{itemize}
\item To make the approach work in practice we added the ability to split up images into smaller tiles each with its own \rstar and \kraster tree.
\item It is mentioned in the paper that a refinement step is needed to reduce it to just one list, but not how to do this. We have implemented this refinement using \kraster search functions based on the ones described in \citetitle{k2raster} by \citet{k2raster}.
\item In the paper, they describe the need for an \textit{extractCells} method, but they do not provide such a method. For searching the \kraster we use a modified version of the search functions described in \citetitle{k2raster}. The new version of these functions allow us to search the \kraster tree much faster.
\item in the part of our implementation corresponding to \textit{extractCells}, we need to find pixels that overlap with the vector data before applying the filter. To do this, we use a modified version of \beast's \textit{extractCells}.
\item More powerful filter functionality in the join algorithm
\item Instead of just an algorithm \raven is a system which contain a few additional features. For example, the visualiser.
\end{itemize}

\subsubsection{Overview}
\ravenjoin is a raster-vector spatial join algorithm. It has support for filtering based on raster values faster than conventional join algorithms that first generate all results and then filter them. The system supports a basic input of TIFF with sidecar files, GeoTIFF and shapefile files. A join is created for each combination of raster and vector files. Specifically for the vector data, \ravenjoin only supports polygons. The initial step of \ravenjoin is to build the required data structures. The first data structure we build is an STR bulk-loaded \rtree. We use this tree to determine what vector data overlaps with a given tile of raster data. To make this work, we have to convert the rectangle describing the area of the given raster tile from the raster data CRS to that of the vector data. The vector data that lies within the bounds will be copied and then projected to the raster data's CRS. Raster bounds that has no intersecting vector data can be skipped. This means the raster data only gets indexed as it is needed for a join. The indices that get created will get stored to disk such that the consecutive joins of the same area, it will use the cached indices instead. 

Next, an \rstar is created for every tile, containing the vector data that overlaps with it. Each tile of raster data is converted to a \kraster tree and it is passed to the join algorithm along with its corresponding \rstar.

The join algorithm itself processes all nodes in the \rstar following a depth first traversal. When processing a node, the algorithm does a simple fast check where it finds the smallest \kraster node that fully contains the \rstar node. It can then examine the minimum and maximum values within that \kraster node. If no values within that range match the filter it can simply ignore the \rstar node. If all values within the range match the filter, it can find the pixels that overlap with the geometries and add all these to a result list.

If some values of the range match the filter and some don't, the algorithm has to perform a slower, but similar, check on the MBR of the node instead. If either all or no values within the MBR fall within the filter given to it, it will do the same thing as with the node check. This time, if only some values in the range match the filter, it will use a method called \textit{search values in ranges} to find only the pixels that do match the filter.

A flowchart of this central part of the algorithm can be seen in figure \ref{fig:join-flow-chart}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/03method/join flow chart.png}
    \caption{A flowchart of the outer routine in the join algorithm \ravenjoin.}
    \label{fig:join-flow-chart}
\end{figure}

\subsubsection{Filtering}
One of the main differences between \raven and \beast is that \raven has greater support for joins that filter the result based on pixel values. We will define a filter as a function that accepts certain pixel values only. When a filter is applied to a join it means that the result of the join will be only the pixels whose values are matches the predicate of the filter and overlap with the vector data.

In \raven, the filter is pushed far down in the join algorithm, making it possible to disregard pixels that will be filtered away earlier. This is a feature of the \kraster nodes of the data structure correspond to an area given the node depth. The nodes contain a minimum and maximum value than can be checked any time in the join. In \beast, no such functionality exists, this means that the only way to apply a filter on the join is to first compute the full join, then filter the result. 

The simplest useful filter is one that can select values within a certain range. That is, the filter should have 2 values $lo$ and $hi$, and for any value $x$ should match $x$ if and only if $lo \leq x \leq hi$.

Another potentially useful filter is one that matches pixels based on multiple samples from the raster data. This could be used to match only those pixels that have a red value in a certain range, a green value in another range, and a blue value in a third range.

The pushing down of the filter is accomplished by querying the \kraster tree for the minimum and maximum pixel value in the area covered by the MBR of a given geometry or collection of geometries. If no values in this section of the \kraster tree are values accepted by the filter, the geometry in question can be thrown away without having to be processed further. 

\raven supports filter functions that can compute whether a given range of values contain (1) any values that should be accepted by the filter, and (2) any values that should not be accepted by the filter. Any filter function should therefore implement 2 methods, one for each of these checks. The reason it is done in this way is that the \kraster tree will give a range of values in the form of a min/max pair for any area queried. This type of filter can therefore be used to figure out if the geometry can be thrown away. This happens if it does not contain any pixels the filter accepts. It can also be used to determine if we can add all pixels within it to the results without having to filter each pixel. This happens when the range does not contain any values the filter will not accept.

The range filter can be implemented in \raven as a filter that for a queried interval $[x_1,x_2]$ returns $x_1 \leq hi \wedge lo \leq x_2$ for check (1) and $x_1 < lo \vee x_2 > hi$ for (2).

In \citetitle{k2rasterjoin} by \citet{k2rasterjoin}, which is the paper our system is based on, only filters of this kind are supported. Our more abstract way of implementing these filters allows us to have more control over which values should be accepted. For example, without changing anything other than which filter object is used, we could easily accept values that fall within one of 2 or more given ranges, by simply composing multiple of these filters with 'or' operations. If many ranges are needed to match all the values we want, an interval tree can be used to give a query time of $O(log(n))$, where $n$ is the number of ranges. Alternatively, if the number of bits used by the pixels is not too high, a prefix sum array can easily be used to filter values in constant time.

Applying a special filter that applies a separate filter for each sample is also possible using a filter function. This can save time over the more naive approach of filtering based on a range that encompasses all the wanted values and then manually filtering the results afterwards. The reason it is faster is not that it saves time on lookups in the \kraster tree, but rather that it produces fewer results initially and avoids the final iteration over the results to further filter them.

\subsubsection{Quadrant Checking}
This is the fast initial check the join algorithm performs for nodes of interest in the \rstar. It works by starting at a given node of the \kraster tree to find the child node that contains the given geometry. It recursively calls itself with the currently found node. If none of the children contain the geometry, it means that the node currently being examined, is the smallest node that does. Once the smallest \kraster node containing the given geometry has been found, its minimum and maximum values can be given to the filter. The filter can then determine if the node in question should be examined further. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{images/03method/checkQuadrant.png}
    \caption{Example showing how checkQuadrant would evaluate the red Polygon. Since there is no full overlap for any of the inner \kraster nodes. The top left outer \kraster node would be returned.}
    \label{fig:check-quadrant}
\end{figure}

\subsubsection{MBR Checking}
This is a slower version of the previous method. The goal of this method is to find the minimum and maximum raster values stored in the part of the \kraster tree that overlaps with the given geometry. We are therefore interested in finding all \kraster nodes that are contained within the given geometry. This is done by a search of the \kraster tree resembling a depth first search. The maximum value stored within the pixels that overlap with the geometries can be found by taking the maximum of the maximum values of all \kraster nodes contained within the geometry. The minimum can be found in a similar way. 

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/03method/checkMBR.png}
    \caption{Example showing which \kraster nodes would be examined to determine the minimum and maximum values. The method would examine the values of the blue nodes(e.g. nodes that are contained within the MBR of the polygon)}
    \label{fig:check-mbr}
\end{figure}

\subsubsection{Result Types}
\label{sec:result-types}
\raven has three possible result type configurations, each with their own respective advantages and drawbacks. 
\paragraph{Values} The value type is similar to that of RaptorJoin. For each geometry that has resulted in a match, a result with the following information is created. 
\begin{itemize}
    \item Filename of the raster image
    \item Geometry that caused the pixel to be included
    \item A list of pixel value and coordinate pairs.
\end{itemize}
This result type is the slowest. This type requires that for each pixel, an object is created and included in the result list. It is also the type that most closely matches the result type of the \raptorjoin algorithm.

\paragraph{RangeValues} The range value result type encodes the same information as the value type above, but instead of individual pixels in the list, it has ranges of pixels that have the same values. A range consists of a row number, a start and stop column, and a value for that range. Using this type, areas that have identical pixel values, are compressed into fewer pixel ranges. Figure \ref{fig:result-type} shows these ranges in a join between \textit{GLC2000} \& \textit{boundaries}. Pixels that have a similar shade, are part of a range with the same length with the exception of the background colour.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\textwidth]{images/03method/ranges.png}
    \caption{RangeValue result type. Darker pixels with the same shade are part of a range with the range specified by the legend.}
    \label{fig:result-type}
\end{figure}

\paragraph{Ranges} The final and fastest result type is ranges. For this type, we again encode the same values as the Value type, however for the list, we only include ranges without values. This also means that in the case of no filter, we can skip looking up values entirely, leading to a much faster join. The only guarantee these results provide in the case of a filter is that the ranges that are included, are within the filter extremes.






\subsubsection{Extract Cells}
\label{sec:extract-cells}
In \citetitle{k2rasterjoin}, the join operation described produces a list of probable results and one of definite results. They describe that in order to reduce this to one list of results, a \textit{refinement step} is needed. In this step, each geometry in the probable result list, is examined more closely to find all pixels within them that match the filter. This step is not described further in their paper.
In \citetitle{k2raster}, methods are provided to efficiently extract values from the \kraster tree. The most interesting one of these is the one they call \textit{search values in window}. It takes as input, a rectangle and returns all pixels within this rectangle that matches the filter. It saves time over getting all pixel values within the window and then using the filter to discard pixels. It uses the filter during the search to avoid exploring parts of the \kraster tree that do not match the filter.

Our initial approach to find all the results, was to first produce both the definite and probable results list like they mention in the paper. Both lists contain pixel ranges that overlap with some polygon. We would then go through all pixel ranges in the probable list and use the \textit{search values in window} method on each row to get only the pixels that match the filter.

A slight improvement to this method was made by only producing one list and performing the last step mentioned above immediately when we would have otherwise added the ranges to the probable results list. This saves time, since we can avoid an additional iteration over all results in the probable results list.

We saw that this method could still be improved, since pixel ranges that lie close to each other would cause multiple calls to the \textit{search values in window} with each call starting out identically. This is because the method in question starts at the root of the tree and recursively queries child nodes that overlap with the given window.

To save time on node lookups, we came up with the idea of giving multiple ranges to a method performing similar work to \textit{search values in window}. We call this function \textit{search values in ranges}. The problem then became allowing the algorithm to quickly determine whether a certain \kraster node contains any of the given ranges. It is not feasible to go through all ranges and find out if they overlap as this would simply take too long.

Instead, we came up with the idea of making multiple calls to \textit{search values in ranges} where at most one range per row is included in each call. This allows us to use a $k$-ary segment tree that can be built quickly and answer queries about the horizontal span of ranges. Queries that contain only ranges within the rows used by a given \kraster node can be answered in constant time. This span can then be used to determine whether the \kraster node overlaps with at least one of the given ranges.

To only give the method one range per row at most, we split the ranges into what we call \textit{layers}. The first layer contains the first pixel range from all rows that have one. The second layer contains the second pixel range from all rows that have at least 2 ranges, and so on. The total number of layers is therefore determined by the number of ranges in the most populated row.

At each node, the tree stores the minimum and maximum x-value of the ranges present in the corresponding subtree. The tree is built by starting at the leaves, where each node that has a range present will be updated to the start and end x-value of that range. For every other node, the start value of it will be the minimum start value of its $k$ children, and the end value will be the maximum of their end values. A node may also have no ranges contained in it, in this case we use infinity as the start value and negative infinity as the end, this way, it is not a valid range, and will not influence any of the values in its parent. An illustration of a tree can be seen in figure \ref{fig:range-tree}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/03method/range tree.pdf}
    \caption{An illustration of how pixel ranges are converted to a range tree. Note that only the tree for the first layer is shown. A second tree would be made for the second ranges in rows 3 and 5. The value of $k$ for this tree is 2.}
    \label{fig:range-tree}
\end{figure}

With this tree, it is still possible that a \kraster tree node falls within the span described by the segment tree without containing any ranges itself. For this to happen, however, one row would have to contain a range all the way on the left side of the raster data, and the very next row has to contain only one range at the very right of the raster data. This will also have to happen multiple times for it to slow down the algorithm significantly. Note that it can only happen if the vector data happens to lie just outside the raster tile on at least 3 sides and only intersects it on one side at a time alternating between the left and right side. We will assume that this happens rarely enough that it has no significant impact on performance.

Pseudocode for the extractCells subroutine can be found in Algorithm \ref{alg:extractCells}.
\begin{figure}[H]
\begin{algorithm}[H]
\caption{\textbf{extractCells}($P$,$pk$) finds all pixels inside a \kraster tree node $pk$ that are contained in a polygon $P$.}\label{alg:extractCells}
$intersections \gets (\emptyset \colon y \in [1..|pk|])$\\
$oldPoint \gets P_{|P|}$\\
\For{$point \in P$}{
    \Comment*[r]{Compute the standard form \\ of the line segment $(point, oldPoint)$}
    $a \gets (point_y - oldPoint_y)$\\
    $b \gets (oldPoint_x - point_x)$\\
    $c \gets a \times oldPoint_x + b \times oldPoint_y$\\

    $minY \gets \min(oldPoint_y,point_y)$\\
    $maxY \gets \max(oldPoint_y,point_y)$\\
    \For{$y \in [minY..maxY]$}{
        $x \gets   \lfloor(c-b*(y+\frac{1}{2})) / a\rfloor$ \Comment*[r]{Finds intersection x ordinate}
        $intersections_y \gets intersections_y \cup \{x\}$
    }
    $oldPoint \gets point$\\
}
$ranges \gets \emptyset$ \\
\For{$y \in [1..|pk|]$}{
    $inRange \gets \FALSE$\\
    $start \gets 0$\\
    \For{$x \in intersections_y$}{
        \eIf{$|\{i\in intersections_y \colon i=x \}|\equiv 0 \mod 2$}{
            \If{$\neg inRange$}{
                $ranges \gets ranges \cup \{(y,[x..x])\}$\\
            }
        }{
            \eIf{$inRange$}{
                $inRange \gets \FALSE$\\
                $ranges \gets ranges \cup \{(y,[start..x])\}$
            }{
                $inRange \gets \TRUE$\\
                $start \gets x$
            }
        }
    } 
}
$out \gets \emptyset$\\
$queryTrees \gets \text{segment tree of range span for each layer}$\\
\For{$tree \in queryTrees$}{
    $out \gets out \cup \text{result of searching the \kraster using $tree$ and $ranges$}$
}


\Return{out}
\end{algorithm}
\caption*{Note that $intersections$ is used as a tuple of multisets, hence the set builder notation on line 21 is used to count the number of appearances of a number $i$ in the $y^{th}$ multiset in $intersections$.}
\end{figure}

\begin{figure}[H]
\begin{algorithm}[H]
\caption{\textbf{searchValuesInRanges}($n$, $r_1$, $c_1$, $r_2$, $c_2$, $filter$, $minval$, $maxval$, $z$, $treeIndex$, $tree$) Finds all values from region $[r_1,r_2] \times [c_1,c_2]$ in the \kraster that match the given filter and are contained in one of the ranges defined by $tree$.}\label{alg:search-within-ranges}
$z \gets rank(T,z)*k^2$\\
\For{$i \gets \floor{r_1/(n/k)}...\floor{r_2/(n/k)} $}{
    \eIf{$i=\floor{r_1/(n/k)}$}{
        $r_1' \gets r_1 \mod (n/k)$
    }{
        $r_1' \gets 0$
    }
    \eIf{$i=\floor{r_2/(n/k)}$}{
        $r_2' \gets r_2 \mod (n/k)$
    }{
        $r_2' \gets (n/k)-1$
    }
    \For{$j \gets \floor{c_1/(n/k)}...\floor{c_2/(n/k)} $}{
        \eIf{$j=\floor{c_1/(n/k)}$}{
            $c_1' \gets c_1 \mod (n/k)$
        }{
            $c_1' \gets 0$
        }
        \eIf{$i=\floor{c_2/(n/k)}$}{
            $c_2' \gets c_2 \mod (n/k)$
        }{
            $c_2' \gets (n/k)-1$
        }
        $z' \gets z +k*i+j$\\
        $maxval' \gets maxval - accessDACs(Lmax,z')$\\
        $treeIndex' = treeIndex * k + i + 1$\\
        \eIf{$z' > |T| \vee T[z'] = 0$} {
            \Comment*[r]{leaf}
            $minval' \gets maxval'$\\
            \If{$filter \cap \{minval'...maxval'\} \neq \emptyset$}{
                \text{Use $tree$ to find and output all cells in this region} \\ \text{that are contained in one of the ranges} \\
                \Continue
            }
        }{
        \Comment*[r]{internal node}
            $minval' \gets minval + accessDACs(Lmin,rank(T,z'))$ \\
            \eIf{$filter \cap \{minval'...maxval'\} = \{minval'...maxval'\}$}{
                \text{Use $tree$ to find and output all cells in this region} \\ \text{that are contained in one of the ranges} \\
                \Continue
            }{
            $searchValuesInRanges(n/k,r_1',c_1',r_2',c_2',$\\
            \Indp \Indp $filter,minval',maxval',z',treeIndex',tree)$\\
            }
        }
    }
}
\end{algorithm}
\caption*{$rank(T,z)$ is defined as the number of ones in the bitmap $T$ up to and including the index $z$. $rank(T,-1)=0$ by definition.}
\end{figure}


\paragraph{Analysis of worst-case performance} under the assumption that the ranges are not placed such that the range tree does not work as intended.

Let $n$ be the side length of the raster image, $k$ be a constant used in the \kraster tree, and $m$ be the number of ranges found by the initial step of the \textit{extract cells} method. Let $q$ denote the average length of these ranges.
Using the old approach, it will do $m$ runs of the search function, which will, in the worst case, have to go through all $log_k(n)$ levels. At the lowest level, they will have to enter at most $q/k$ nodes at the last level, then $q/k^2$ and so on. At each recursive call, they will have to perform approximately $k^2$ work, as they will look at all possible candidates for further recursion. The sum of work done for one initial call of the function is:

\[\sum_{i=1}^{log_k(n)} q*k^2/(k^i) = k^2(n-1)q/(k-1)n \approx k*q \]

Let $t_{old}$ denote the running time of the old approach in full, it is equal to the time taken by a single range multiplied by the number of ranges.
\begin{equation}
t_{old} \approx k*q*m
\label{equation:old-running-time}
\end{equation}

With the new approach, we will have to make sure we don't explore parts of the matrix that don't contain any pixel ranges. To do this, we use the segment tree explained earlier. Building this tree takes time $t_{tree}$.

\begin{equation}
t_{tree} = \sum_{i=0}^{log_k(n)} n/k^i = k(n-1)/(k-1) < 2*n
\label{equation:tree-build-time}
\end{equation}

We do however save some time not having to go from the root of the \kraster tree for every new range. The reason for this is that even if new ranges are placed in the most malicious row possible, the method will be able to reuse some higher \kraster nodes for most of the ranges. Only the first $k^2$ ranges added to the list will take the full $k*q$ time. The next $k^2 (k^2-1)$ in the worst case will save at least one lookup each, since each of the recursive calls at the first level would be able to reuse a node. The next $k^4 (k^2-1)$ ranges will save at least two lookups. In general, the $i$-th range added will take time approximately $k*q-log_{k^2}(i) + 1$ at worst, where $log_{k^2}(i) - 1$ is a lower bound on the number of node lookups we can save. Note that this is quite a pessimistic lower bound, as it is unlikely that the ranges will be placed in the worst way possible. It is much more likely that the ranges will be placed next to each other, in which case the savings are even greater.

The new approach splits the calls into a number of layers. We will assume there are $l$ such layers and the $i$-th layer contains $m_i$ ranges. Then m can be computed as follows.
\begin{equation}
\sum_{i=0}^l (m_i) = m
\label{equation:m-sum}
\end{equation}

If we want to consider how long adding all $m_i$ ranges for the $i$-th layer will take in the worst case, we can compute the following sum:
\begin{equation}
    \begin{aligned}
        t_i = \sum_{j=1}^{m_i} k*q-log_{k^2}(j) + 1 = k*q*m_i - log_{k^2}(m_i!) + m_i \\
        \approx k*q*m_i - m_i*log_{k^2}(m_i)
    \end{aligned}
\label{equation:time-range-i}
\end{equation}
The time taken by the new approach in full we will denote $t_{new}$. It can be expressed as the sum of all $t_i$ with an added term $l*2*n$ to account for the time taken to build the $l$ trees.
\begin{equation}
t_{new} = l*2*n + \sum_{i=0}^l t_i \approx l*2*n + \sum_{i=0}^l k*q*m_i - m_i*log_{k^2}(m_i)
\label{equation:new-running-time}
\end{equation}

The worst case for our new approach is when $l=m$, this will only happen when all ranges are in a single row and is therefore very unlikely. We can see by setting $l=m$ in equation \ref{equation:new-running-time} that even in this extreme case, we will only take time
\[2*m*n + k*m*q\]
This means that we will use an extra $2*m*n$ time over the old approach but this will happen very rarely, and even when it does, $m$ is likely to be very small. This is because if $l=m$ that must mean that only one of the outer rows are used. That means that a shape is mostly outside the raster data, and its outline crosses the raster bounding box $2*m$ times. For large $m$ this is very unlikely.

If we instead assume that $l=1$, it follows from equations \ref{equation:new-running-time} that the new approach uses at most
\[2*n + k*m*q - m*log_{k^2}(m)\] time. Here, the $2*n$ time is spent building the tree, and the rest is for the call to \textit{search values in ranges}. In practise, $l$ will not always be 1, but it is likely to be very small.

We will instead assume that $\forall i<l | m_i=m/l$, that is, the pixel ranges are spread evenly among all layers. Then, the total time taken is approximately
\begin{equation}
    \begin{aligned}
         t_{new} \approx l * (2*n + k*q*m/l - m/l*log_{k^2}(m/l)) \\
        = 2*n*l + k*q*m - m*(log_{k^2}(m)-log_{k^2}(l))
    \end{aligned}
\label{equation:new-running-time-low-l}
\end{equation}
We can see here, that as long as $l$ is small, we don't lose significant performance over having just one layer.


To summarise, our new approach is not asymptotically slower than the old approach under the following 2 assumptions:
\begin{itemize}
    \item the number of layers is likely to be small. In this case, small means bounded by a constant. This also means that a large number of ranges will not occupy only a few rows.
    \item it is unlikely that ranges will appear only on the outside of the raster data alternating between the left and the right side for many of the rows.
\end{itemize}

The old approach has a worst-case running time of at most \[k*m*q\] as can be seen by equation \ref{equation:old-running-time}. The new approach has a worst case running time of approximately \[2*n*l + 2*m*q - m*(log_{k^2}(m)-log_{k^2}(l))\] as can be seen by equation \ref{equation:new-running-time-low-l}.
This means that the savings in terms of running time is
\[\Delta t \propto m*log(m) - n\]
in the worst case, under the assumptions mentioned. There is therefore at least a theoretical advantage to using our new method, since we think these assumptions are reasonable. The practical advantage is examined in the evaluation section \ref{sec:k2searchcomparison}.


\subsubsection{Out of Core Execution}

To achieve out of core execution we partition the raster data into fixed sized squares. We can then process one square at a time without having the rest of them loaded in memory. This means it is important that the raster data is only read in these same portions for each partition. Since we know the bounds of the tiles, we can exclude vector data for each tile before the join. For any given values of $k$ in the \kraster, the optimal tile size will be a power of $k$. At the same time small tile sizes will accumulate too much overhead. The tiles are the initializing point of a stream that can be parallelized. The tiles will receive their own raster readers that work on an independent level, which does not need synchronization.
This approach also allows \raven to use almost no memory other than what is needed to store the vector data. The effects of this are examined in section \ref{sec:memory}.


\subsubsection{Caching}
The approach of creating fixed-sized partitions of the raster data allows the data structures to be cached in a replacing fashion in the sense that the cache can be created partially as needed. The logical coverage of each cache makes it easy to manage the reusability of the cache. If the data structures were created from the least required raster data for one join, it could require more work to create the uncached raster.

We only cache the \kraster while the \rtree gets rebuild given the vector data. The reason being, the use case of the system is that the raster data is used with many different vector datasets and therefore the vector data is not the same between each join. However, it could be an option to cache these structures too for the purpose of doing different filters.

\subsection{Visualizer} \label{sec:visualiser}

The \raven system contains a visualizer which is helpful for checking correctness and finding bugs in the implementation. If a join takes longer or shorter than expected, the visualizer can also help make it clearer why that happened. Any drawing done by the visualizer can use at least either a single colour or randomly generated colours. The visualizer supports the following operations
\begin{itemize}
    \item Drawing the result created by the \ravenjoin algorithm. In addition to the two other colour types, this can be also done using the original colour scheme from the raster file.
    \item Drawing the nodes of the \kraster tree.
    \item Drawing the MBR of the nodes of the \rstar.
    \item It can also draw the vector data on top of any of the previous.
\end{itemize}

In figure \ref{fig:join-example} it is showcased how a join is visualized. Every cell of the raster data inside the polygons are reconstructed in an image. 


\begin{figure}[H]
    \centering   %
\setkeys{Gin}{width=\linewidth}
\begin{subfigure}{.45\textwidth}
  \includegraphics{images/03method/visualiser/GLC raw.png}
  \caption{Snippet of Europe from the GLC2000 raster dataset.}
  \label{fig:BC}
\end{subfigure}
\hfil
\begin{subfigure}{.45\textwidth}
  \includegraphics{images/03method/visualiser/protected areas.png}
  \caption{The vector dataset Protected Areas.\\ \mbox{}}
  \label{fig:DC}
\end{subfigure}

\begin{subfigure}{.8\textwidth}
  \includegraphics{images/03method/visualiser/GLC join.png}
  \caption{The drawn result of joining GLC2000 and Protected Areas.}
  \label{fig:EC}
\end{subfigure}%
\caption{A visualisation of a join, highlighting the ability to visualise results using the original colours of the image}
\label{fig:join-example}
\end{figure}